{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0904d338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_non_numeric': 6,\n",
       " 'share_class0': np.float64(0.759),\n",
       " 'mean_fnlwgt_train': np.float64(189600.243),\n",
       " 'f1_base': 0.373,\n",
       " 'mean_fnlwgt_train_scaled': np.float64(0.12),\n",
       " 'f1_scaled': 0.516,\n",
       " 'cat_hist_feature': 'native-country',\n",
       " 'n_rows_with_missing': 1914,\n",
       " 'n_features_after_dummies': 75,\n",
       " 'f1_nona': 0.606,\n",
       " 'f1_imp': 0.626}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv(\"adult_data_train.csv\")\n",
    "df = df.drop(columns=[\"education\", \"marital-status\"])\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "non_num_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "n_non_numeric = len(non_num_cols)\n",
    "\n",
    "share_class0 = df[\"label\"].value_counts(normalize=True)[0]\n",
    "\n",
    "X_num = df[num_cols.drop(\"label\")]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_num, y, test_size=0.2, random_state=109, stratify=y\n",
    ")\n",
    "\n",
    "mean_fnlwgt_train = X_train[\"fnlwgt\"].mean()\n",
    "\n",
    "knn_base = KNeighborsClassifier()\n",
    "knn_base.fit(X_train, y_train)\n",
    "f1_base = f1_score(y_test, knn_base.predict(X_test))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_train_s_df = pd.DataFrame(X_train_s, columns=X_train.columns)\n",
    "mean_fnlwgt_train_scaled = X_train_s_df[\"fnlwgt\"].mean()\n",
    "\n",
    "knn_scaled = KNeighborsClassifier()\n",
    "knn_scaled.fit(X_train_s, y_train)\n",
    "f1_scaled = f1_score(y_test, knn_scaled.predict(X_test_s))\n",
    "\n",
    "cat_hist_feature = \"native-country\"\n",
    "\n",
    "mask_missing = (df == \"?\").any(axis=1)\n",
    "n_rows_with_missing = int(mask_missing.sum())\n",
    "\n",
    "df_nona = df[~mask_missing].copy()\n",
    "X_nona = pd.get_dummies(df_nona.drop(columns=[\"label\"]), drop_first=True)\n",
    "y_nona = df_nona[\"label\"]\n",
    "n_features_after_dummies = X_nona.shape[1]\n",
    "\n",
    "X_train_n, X_test_n, y_train_n, y_test_n = train_test_split(\n",
    "    X_nona, y_nona, test_size=0.2, random_state=109, stratify=y_nona\n",
    ")\n",
    "\n",
    "scaler_n = MinMaxScaler()\n",
    "X_train_n_s = scaler_n.fit_transform(X_train_n)\n",
    "X_test_n_s = scaler_n.transform(X_test_n)\n",
    "\n",
    "knn_nona = KNeighborsClassifier()\n",
    "knn_nona.fit(X_train_n_s, y_train_n)\n",
    "f1_nona = f1_score(y_test_n, knn_nona.predict(X_test_n_s))\n",
    "\n",
    "df_imp = df.copy()\n",
    "for col in [\"workclass\", \"occupation\", \"native-country\"]:\n",
    "    mode = df_imp.loc[df_imp[col] != \"?\", col].mode()[0]\n",
    "    df_imp.loc[df_imp[col] == \"?\", col] = mode\n",
    "\n",
    "X_imp = pd.get_dummies(df_imp.drop(columns=[\"label\"]), drop_first=True)\n",
    "y_imp = df_imp[\"label\"]\n",
    "\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_imp, y_imp, test_size=0.2, random_state=109, stratify=y_imp\n",
    ")\n",
    "\n",
    "scaler_i = MinMaxScaler()\n",
    "X_train_i_s = scaler_i.fit_transform(X_train_i)\n",
    "X_test_i_s = scaler_i.transform(X_test_i)\n",
    "\n",
    "knn_imp = KNeighborsClassifier()\n",
    "knn_imp.fit(X_train_i_s, y_train_i)\n",
    "f1_imp = f1_score(y_test_i, knn_imp.predict(X_test_i_s))\n",
    "\n",
    "results = {\n",
    "    \"n_non_numeric\": n_non_numeric,\n",
    "    \"share_class0\": round(share_class0, 3),\n",
    "    \"mean_fnlwgt_train\": round(mean_fnlwgt_train, 3),\n",
    "    \"f1_base\": round(f1_base, 3),\n",
    "    \"mean_fnlwgt_train_scaled\": round(mean_fnlwgt_train_scaled, 3),\n",
    "    \"f1_scaled\": round(f1_scaled, 3),\n",
    "    \"cat_hist_feature\": cat_hist_feature,\n",
    "    \"n_rows_with_missing\": n_rows_with_missing,\n",
    "    \"n_features_after_dummies\": n_features_after_dummies,\n",
    "    \"f1_nona\": round(f1_nona, 3),\n",
    "    \"f1_imp\": round(f1_imp, 3),\n",
    "}\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
